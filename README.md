# ü§ñ MLOps Platform on AWS

[![MLOps](https://img.shields.io/badge/MLOps-Platform-blue?style=for-the-badge&logo=amazon-aws)](https://github.com/melorga/ml-platform-aws)
[![Terraform](https://img.shields.io/badge/Terraform-1.8+-purple?style=for-the-badge&logo=terraform)](https://terraform.io)
[![SageMaker](https://img.shields.io/badge/Amazon-SageMaker-orange?style=for-the-badge&logo=amazon-aws)](https://aws.amazon.com/sagemaker/)
[![EKS](https://img.shields.io/badge/Amazon-EKS-orange?style=for-the-badge&logo=kubernetes)](https://aws.amazon.com/eks/)

A comprehensive, enterprise-grade MLOps platform built on AWS services that demonstrates end-to-end machine learning lifecycle management with automated training, validation, deployment, and monitoring.

## üèóÔ∏è Architecture Overview

```mermaid
graph TB
    subgraph "Data Layer"
        S3[(S3 Data Lake)]
        FS[SageMaker Feature Store]
        RDS[(RDS Metadata)]
    end
    
    subgraph "ML Development"
        SM[SageMaker Studio]
        NB[Notebooks]
        EXP[Experiments]
    end
    
    subgraph "ML Pipeline"
        SF[Step Functions]
        SP[SageMaker Pipelines]
        MR[Model Registry]
    end
    
    subgraph "Model Serving"
        EP[SageMaker Endpoints]
        EKS[EKS Cluster]
        ALB[Application Load Balancer]
    end
    
    subgraph "Monitoring & Ops"
        CW[CloudWatch]
        MM[Model Monitor]
        XR[X-Ray Tracing]
    end
    
    S3 --> FS
    FS --> SM
    SM --> SP
    SP --> MR
    MR --> EP
    MR --> EKS
    EP --> MM
    EKS --> ALB
    MM --> CW
    SF --> SP
    EXP --> RDS
```

## üîÑ ML Lifecycle Management

```mermaid
flowchart LR
    A[Data Ingestion] --> B[Feature Engineering]
    B --> C[Model Training]
    C --> D[Model Validation]
    D --> E{Quality Gate}
    E -->|Pass| F[Model Registration]
    E -->|Fail| G[Retrain]
    G --> C
    F --> H[Staging Deployment]
    H --> I[A/B Testing]
    I --> J{Performance OK?}
    J -->|Yes| K[Production Deployment]
    J -->|No| L[Rollback]
    K --> M[Monitoring]
    M --> N{Drift Detected?}
    N -->|Yes| O[Alert]
    N -->|No| M
    O --> P[Auto Retrain]
    P --> C
```

## üéØ Key Features

### üîß **Infrastructure as Code**
- Complete Terraform modules for all AWS ML services
- Multi-environment support (dev/stage/prod)
- Automated resource provisioning and scaling

### ü§ñ **Automated ML Pipelines**
- SageMaker Pipelines for training workflows
- Step Functions for complex orchestration
- EventBridge-triggered automated retraining

### üìä **Model Management**
- Centralized model registry with versioning
- A/B testing infrastructure
- Blue/green deployment strategies

### üìà **Monitoring & Observability**
- Real-time model performance monitoring
- Data drift detection and alerting
- Comprehensive logging and tracing

### üîí **Security & Compliance**
- IAM roles with principle of least privilege
- VPC isolation and network security
- Encryption at rest and in transit

## üìÅ Repository Structure

```
ml-platform-aws/
‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îú‚îÄ‚îÄ sagemaker-platform/     # Core SageMaker infrastructure
‚îÇ   ‚îú‚îÄ‚îÄ ml-pipelines/           # Training and inference pipelines
‚îÇ   ‚îî‚îÄ‚îÄ model-serving/          # Model deployment infrastructure
‚îú‚îÄ‚îÄ infrastructure/
‚îÇ   ‚îú‚îÄ‚îÄ environments/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dev/               # Development environment
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stage/             # Staging environment
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prod/              # Production environment
‚îÇ   ‚îî‚îÄ‚îÄ shared/                # Shared resources
‚îú‚îÄ‚îÄ examples/
‚îÇ   ‚îú‚îÄ‚îÄ end-to-end-ml-pipeline/ # Complete ML workflow example
‚îÇ   ‚îî‚îÄ‚îÄ model-deployment/       # Model serving examples
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ architecture/          # Architecture documentation
‚îÇ   ‚îî‚îÄ‚îÄ tutorials/             # Step-by-step guides
‚îú‚îÄ‚îÄ scripts/                   # Utility scripts
‚îî‚îÄ‚îÄ tests/                     # Infrastructure tests
```

## üöÄ Quick Start

### Prerequisites
- AWS CLI configured with appropriate permissions
- Terraform >= 1.8.0
- Docker (for local testing)
- Python 3.9+ (for Lambda functions)

### 1. Deploy Core Infrastructure

```bash
# Clone the repository
git clone https://github.com/melorga/ml-platform-aws.git
cd ml-platform-aws

# Deploy to development environment
cd infrastructure/environments/dev
terraform init
terraform plan
terraform apply
```

### 2. Run Example ML Pipeline

```bash
# Deploy example pipeline
cd examples/end-to-end-ml-pipeline
terraform init
terraform apply

# Execute training pipeline
aws stepfunctions start-execution \
  --state-machine-arn $(terraform output pipeline_arn) \
  --input '{}'
```

### 3. Monitor Pipeline Execution

```bash
# View pipeline status
aws stepfunctions describe-execution \
  --execution-arn <execution-arn>

# Check model registry
aws sagemaker list-model-packages \
  --model-package-group-name demo-model-group
```

## üõ†Ô∏è Infrastructure Modules

### SageMaker Platform Module

**Location**: `modules/sagemaker-platform/`

**Components**:
- SageMaker Studio Domain with user profiles
- Feature Store for feature management
- Model Registry for model versioning
- Processing and training job configurations

### ML Pipelines Module

**Location**: `modules/ml-pipelines/`

**Components**:
- Step Functions state machines
- SageMaker Pipeline definitions
- EventBridge rules for automation
- Lambda functions for orchestration

### Model Serving Module

**Location**: `modules/model-serving/`

**Components**:
- SageMaker real-time endpoints
- EKS cluster for batch inference
- Auto-scaling configurations
- Load balancers and networking

## üìä Cost Optimization

### Estimated Monthly Costs (USD)

| Component | Dev | Stage | Prod |
|-----------|-----|-------|------|
| SageMaker Studio | $50 | $100 | $200 |
| Training Jobs | $100 | $300 | $800 |
| Endpoints | $200 | $500 | $1,500 |
| EKS Cluster | $150 | $300 | $600 |
| Storage (S3/EFS) | $20 | $50 | $150 |
| **Total** | **$520** | **$1,250** | **$3,250** |

### Cost Optimization Features
- Spot instances for training jobs
- Auto-scaling for endpoints
- Lifecycle policies for data storage
- Scheduled shutdown for development resources

## üîê Security Features

- **Identity & Access Management**
  - Fine-grained IAM roles and policies
  - Resource-based permissions
  - Cross-account access controls

- **Network Security**
  - VPC isolation with private subnets
  - Security groups and NACLs
  - VPC endpoints for AWS services

- **Data Protection**
  - Encryption at rest (S3, EBS, RDS)
  - Encryption in transit (TLS/SSL)
  - Key management with AWS KMS

- **Compliance**
  - CloudTrail logging
  - Config rules for compliance monitoring
  - GuardDuty for threat detection

## üìà Performance Metrics

### Training Performance
- **Model Training Time**: 15-45 minutes (depending on data size)
- **Pipeline Execution Time**: 2-8 hours (end-to-end)
- **Resource Utilization**: 85-95% (optimized instance types)

### Inference Performance
- **Real-time Latency**: <100ms (P99)
- **Batch Throughput**: 10K+ predictions/minute
- **Availability**: 99.9% SLA

## üß™ Testing

```bash
# Run infrastructure tests
cd tests
go test -v ./...

# Run integration tests
python -m pytest tests/integration/

# Performance testing
cd scripts
./load_test.sh
```

## üìö Documentation

- [Architecture Deep Dive](docs/architecture/README.md)
- [Deployment Guide](docs/tutorials/deployment.md)
- [ML Pipeline Tutorial](docs/tutorials/ml-pipeline.md)
- [Monitoring Guide](docs/tutorials/monitoring.md)
- [Troubleshooting](docs/tutorials/troubleshooting.md)

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Run the test suite
6. Submit a pull request

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üèÜ Portfolio Impact

This MLOps platform demonstrates:

‚úÖ **Enterprise-grade ML infrastructure** design and implementation  
‚úÖ **Advanced AWS services integration** (SageMaker, EKS, Step Functions)  
‚úÖ **Infrastructure as Code** best practices with Terraform  
‚úÖ **MLOps pipeline automation** with CI/CD integration  
‚úÖ **Cost optimization** and performance engineering  
‚úÖ **Security and compliance** in ML workloads  

---

**Built with ‚ù§Ô∏è by [melorga](https://github.com/melorga) as part of an advanced AWS Solutions Architect portfolio**
